import asyncio
import os
import json
import logging
from typing import List, Dict
from dotenv import load_dotenv
from openai import OpenAI

# Project Imports
import sys
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Import ONLY safe tools
from services.agents.recommendation.recommendation_tools import search_jobs_logic

load_dotenv()
client = OpenAI()

# --- Configurations ---
TEST_CASES = [
    {
        "name": "General_Alignment",
        "profile": {
            "summary": "ì €ëŠ” ì»´í“¨í„° ê³µí•™ì„ ì „ê³µí–ˆê³ , ë°±ì—”ë“œ ê°œë°œì— ê´€ì‹¬ì´ ë§ìŠµë‹ˆë‹¤.",
            "goals": ["ë°±ì—”ë“œ ê°œë°œì"],
            "personality": "ì„±ì‹¤í•¨, ë…¼ë¦¬ì ",
            "risks": []
        },
        "description": "ì¼ë°˜ì ì¸ ëª…í™•í•œ ëª©í‘œ"
    },
    {
        "name": "Complex_Needs",
        "profile": {
            "summary": "ì‚¬ëŒ ë§Œë‚˜ëŠ” ê²ƒì„ ì¢‹ì•„í•˜ê³ , ë§ì„ ì˜ í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ê¸°ìˆ ì ì¸ ì§€ì‹ë„ í™œìš©í•˜ê³  ì‹¶ì–´ìš”.",
            "goals": ["ê¸°ìˆ  ì˜ì—…", "IT ì»¨ì„¤í„´íŠ¸"],
            "personality": "ì™¸í–¥ì (E), ì„¤ë“ë ¥ ìˆìŒ",
            "risks": ["í•˜ë£¨ì¢…ì¼ ì½”ë”©ë§Œ í•˜ëŠ” ê²ƒ"]
        },
        "description": "ë³µí•© ë‹ˆì¦ˆ (ê°œë°œ ì§€ì‹ + ì˜ì—… ì„±í–¥)"
    },
    {
        "name": "Conflicting_Constraint",
        "profile": {
            "summary": "ì•ˆì •ì ì¸ ì§ì—…ì„ ì›í•˜ì§€ë§Œ, ë£¨í‹´í•œ ì—…ë¬´ëŠ” ì‹«ê³  ì°½ì˜ì ì¸ ì¼ì„ í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.",
            "goals": ["ê³µë¬´ì›", "ì˜ˆìˆ ê°€"], 
            "personality": "ì°½ì˜ì , ì•ˆì • ì¶”êµ¬",
            "risks": ["ì§€ë£¨í•¨", "ë¶ˆì•ˆì •í•¨"]
        },
        "description": "ìƒì¶©ë˜ëŠ” ëª©í‘œ (ì•ˆì •ì„± vs ì°½ì˜ì„±)"
    }
]

async def run_baseline_logic(profile):
    """
    Simulates the 'Before' state: Raw Hybrid Search without Reasoning
    """
    print(f"   [Baseline] Searching for: {profile['summary'][:20]}...")
    try:
        # 1. Search (Hybrid)
        jobs = search_jobs_logic(profile["summary"], profile["goals"], top_k=3)
        
        # 2. Extract Top 3
        results = []
        if jobs and "matches" in jobs:
            for match in jobs["matches"]:
                title = match["metadata"].get("title") or match["metadata"].get("jobName") or "Unknown Job"
                results.append({
                    "title": title,
                    "score": match["score"],
                    "reasoning": "N/A" 
                })
        return results
    except Exception as e:
        print(f"Baseline error: {e}")
        return []

async def run_agent_simulation(profile):
    """
    Simulates the 'After' state: Agent Logic (Simulated via LLM to bypass local deps)
    """
    print(f"   [Agent] Thinking for: {profile['summary'][:20]}...")
    
    # This prompt MIMICS the real Agent's instructions
    user_msg = f"""
    You are an AI Career Agent.
    User Profile:
    - Summary: {profile['summary']}
    - Goals: {json.dumps(profile['goals'], ensure_ascii=False)}
    - Personality: {profile['personality']}
    - Risks (Avoid): {json.dumps(profile['risks'], ensure_ascii=False)}
    
    Task:
    1. Recommend top 3 jobs.
    2. STRICT RULE: Explore diverse options that bridge specific goals and personality.
    3. Provide specific reasoning for each.
    
    Return JSON: {{ "jobs": [ {{ "title": "...", "reasoning": "..." }} ] }}
    """
    
    try:
        sim_res = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": user_msg}],
            response_format={"type": "json_object"}
        )
        data = json.loads(sim_res.choices[0].message.content)
        
        results = []
        for item in data.get("jobs", [])[:3]:
            results.append({
                "title": item["title"],
                "score": 0.95, 
                "reasoning": item.get("reasoning", "Generated by Agent")
            })
        return results

    except Exception as e:
        print(f"Agent error: {e}")
        return []

async def evaluate_with_llm(case, baseline_results, agent_results):
    prompt = f"""
    Compare these two recommendation sets for the User Profile.
    
    User Profile: {json.dumps(case['profile'], ensure_ascii=False)}
    
    [Baseline Results (Before)]
    {json.dumps(baseline_results, ensure_ascii=False)}
    
    [Agent Results (After)]
    {json.dumps(agent_results, ensure_ascii=False)}
    
    Evaluate (1-5):
    1. Alignment: Do outcomes match specific goals/nuances?
    2. Reasoning: Is the reasoning logical? (Baseline = 1 if none)
    
    Return JSON: {{ "baseline_alignment": int, "baseline_reasoning": int, "agent_alignment": int, "agent_reasoning": int, "critique": "string" }}
    """
    
    res = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"}
    )
    return json.loads(res.choices[0].message.content)

async def main():
    print("# ğŸ“Š Recommendation Quality Comparison Report\n")
    print(f"| Test Case | Metric | Before (Search) | After (Agent) | Insight |")
    print(f"| :--- | :--- | :--- | :--- | :--- |")
    
    for case in TEST_CASES:
        res_base = await run_baseline_logic(case['profile'])
        res_agent = await run_agent_simulation(case['profile'])
        
        score = await evaluate_with_llm(case, res_base, res_agent)
        
        # Table Row 1: Alignment
        print(f"| **{case['name']}** | Alignment | {score['baseline_alignment']}/5 | **{score['agent_alignment']}/5** | {score['critique']} |")
        # Table Row 2: Reasoning
        print(f"| | Reasoning | {score['baseline_reasoning']}/5 | **{score['agent_reasoning']}/5** | Explains *Why* |")

if __name__ == "__main__":
    asyncio.run(main())
